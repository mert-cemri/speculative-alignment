{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import norm_logits, sample, max_fn, Decoder\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import create_models, color_print\n",
    "\n",
    "MODELZOO = {\n",
    "    # llama-1\n",
    "    # https://huggingface.co/PY007/TinyLlama-1.1B-step-50K-105b\n",
    "    \"llama1b\": \"/share_nfs/fangjiarui/root/code/hf_models/TinyLlama-1.1B-step-50K-105b\",\n",
    "    \"llama7b\": \"/share_nfs/tianzhi/code/llama-7b\",\n",
    "    \"llama30b\": \"/share_nfs/fangjiarui/root/code/hf_models/llama-30b-hf\",\n",
    "    \"llama2-7b\" : \"/share_nfs/fangjiarui/root/code/hf_models/llama-2-7b-hf\",\n",
    "    \"llama2-70b\" : \"/share_nfs/fangjiarui/root/code/hf_models/llama-2-70b-hf\",\n",
    "    \"llama3-8b\":\"solidrust/Meta-Llama-3-8B-Instruct-AWQ\",\n",
    "    \"llama3-13b\":\"solidrust/Llama-3-13B-Instruct-v0.1-AWQ\",\n",
    "    \"bloom-560m\": \"/share_nfs/fangjiarui/root/code/hf_models/bloom-560m\",\n",
    "    \"bloom7b\": \"/share_nfs/fangjiarui/root/code/hf_models/bloomz-7b1\",\n",
    "    \"baichuan-7b\": \"/share_nfs/duanqiyuan/models/source_models/hf/baichuan-7B\",\n",
    "    \"baichuan-13b\": \"/share_nfs/duanqiyuan/models/source_models/hf/Baichuan-13B-Base\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0282d46dffd42e596163655e453f6a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "device = \"cuda:3\"\n",
    "model_name = \"Skywork/Skywork-Reward-Llama-3.1-8B\"\n",
    "# model_name = \"Skywork/Skywork-Reward-Gemma-2-27B\"\n",
    "rm = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=device,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    "    num_labels=1,\n",
    ")\n",
    "rm_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "def return_reward(question,answer):\n",
    "    if question == None:\n",
    "        conv1 = [{\"role\": \"assistant\", \"content\": answer}]\n",
    "    else:\n",
    "        conv1 = [{\"role\": \"user\", \"content\": question}, {\"role\": \"assistant\", \"content\": answer}]\n",
    "    conv1_formatted = rm_tokenizer.apply_chat_template(conv1, tokenize=False)\n",
    "    conv1_tokenized = rm_tokenizer(conv1_formatted, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        score1 = rm(**conv1_tokenized).logits[0][0].item()\n",
    "    return score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====doing tokenizer\n",
      "begin loading models: \n",
      " solidrust/Meta-Llama-3-8B-Instruct-AWQ \n",
      " solidrust/Llama-3-13B-Instruct-v0.1-AWQ\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e342fb6cce0247a5b9319cb3b3b05458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f8bcffea8d47ae8b6dee6aed1e2baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish loading models\n"
     ]
    }
   ],
   "source": [
    "draft_model, target_model, tokenizer = create_models(MODELZOO[\"llama3-8b\"], MODELZOO[\"llama3-13b\"],device=rm.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_children = 2\n",
    "exploration_weight = 1.41\n",
    "import math\n",
    "import random\n",
    "\n",
    "class Node:\n",
    "    def __init__(self,question,answer,prev_answers='',parent=None):\n",
    "        global node_count\n",
    "        self.question = question\n",
    "        self.answer = answer\n",
    "        self.prev_answers = prev_answers\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        self.reward = 0.0\n",
    "        self.value = 0.0\n",
    "        self.visits = 0\n",
    "        self.name = node_count\n",
    "        node_count += 1\n",
    "\n",
    "    def is_fully_expanded(self):\n",
    "        # check if we can expand further\n",
    "        return len(self.children) >= max_children\n",
    "    \n",
    "    def best_child(self):\n",
    "        #return index of best child\n",
    "        choice_weights = []\n",
    "        for child in self.children:\n",
    "            if child.visits == 0:\n",
    "                weight = float('inf')\n",
    "            else:\n",
    "                weight = child.value/child.visits + exploration_weight* math.sqrt((2*math.log(self.visits) / child.visits))\n",
    "            choice_weights.append(weight)\n",
    "        return self.children[np.argmax(choice_weights)] \n",
    "    \n",
    "    def most_visited_child(self):\n",
    "        # return most visited child\n",
    "        return max(self.children, key=lambda child:child.visits)\n",
    "    \n",
    "    def add_child(self,child_node):\n",
    "        # add child_node to current node\n",
    "        self.children.append(child_node)\n",
    "        child_node.parent = self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeSearch:\n",
    "    def __init__(self,prefix,max_iterations=3):\n",
    "        self.prefix = prefix\n",
    "        self.max_iterations = max_iterations\n",
    "    \n",
    "    def search(self):\n",
    "        for i in range(self.max_iterations):\n",
    "            # print(f\"Iteration: {i}/{self.max_iterations}\")\n",
    "            node = self.select(self.root)\n",
    "            # print(f\"Selected node: {node.name}\")\n",
    "            if node.visits > 0:\n",
    "                node = self.expand(node)\n",
    "            # if not node.is_fully_expanded():\n",
    "            #     node = self.expand(node)\n",
    "            node.reward = self.evaluate(node)\n",
    "            # print(f\"Assigned reward for node {node.name} is: {node.reward}\")\n",
    "            self.backpropagate(node)\n",
    "        return self.best_node\n",
    "    \n",
    "    def select(self, node):\n",
    "        while node.is_fully_expanded() and node.children:\n",
    "            # if node has a child and it is fully expanded, go deep\n",
    "            # if at a leaf or not fully expanded, return that node and expand\n",
    "            node = node.best_child()\n",
    "        return node\n",
    "\n",
    "    def expand(self, node):\n",
    "        for j in range(max_children - len(node.children)):\n",
    "            child_answer = get_answer(self.question, node.prev_answers)\n",
    "            child_node = Node(self.question, answer=child_answer, prev_answers=node.prev_answers+node.answer)\n",
    "            node.add_child(child_node)\n",
    "            # print(f'Added a new node {child_node.name} to node {node.name}')            \n",
    "        return random.choice(node.children)\n",
    "\n",
    "    def evaluate(self, node):\n",
    "        return return_reward(self.prefix, node.answer)\n",
    "    \n",
    "    def backpropagate(self, node):\n",
    "        while node is not None:\n",
    "            node.visits += 1\n",
    "            node.value += node.reward\n",
    "            if node.value/node.visits > self.best_value:\n",
    "                self.best_value = node.value/node.visits\n",
    "                self.best_node = node\n",
    "            node = node.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text ='cat hopped'\n",
    "prefix = tokenizer.encode(input_text, return_tensors='pt').to(draft_model.device)\n",
    "approx_model = draft_model\n",
    "target_model = target_model \n",
    "max_len = 5 \n",
    "gamma = 4\n",
    "temperature = 1\n",
    "top_k = 0\n",
    "top_p : float = 0 \n",
    "random_seed = None\n",
    "reward_coeff = 0.01\n",
    "\n",
    "def leveled_tree(target_model, x, num_samples=3, levels=2):\n",
    "    all_drafts = []\n",
    "    current_level = 0\n",
    "    drafts_by_level = {0:[x]}\n",
    "    while current_level < levels:\n",
    "        new_level_drafts = []\n",
    "        for draft in drafts_by_level[current_level]:\n",
    "            q_logits = target_model(draft).logits\n",
    "            normalized_logits = norm_logits(q_logits[:, -1, :], temperature, top_k, top_p)\n",
    "            next_tok = sample(normalized_logits,num_samples=num_samples)\n",
    "            current_drafts = [torch.cat((draft, next_tok[:,i:i+1]), dim=1) for i in range(num_samples)]\n",
    "            new_level_drafts += current_drafts\n",
    "        current_level += 1\n",
    "        drafts_by_level[current_level] = new_level_drafts\n",
    "\n",
    "    rewards = torch.zeros(len(drafts_by_level[levels]),device=x.device)\n",
    "    probs = torch.zeros(len(drafts_by_level[levels]),device=x.device)\n",
    "    for i in range(len(drafts_by_level[levels])):\n",
    "        rewards[i] = return_reward(None, drafts_by_level[levels][i])\n",
    "        # print(f\"drafts_by_level[levels][i], {drafts_by_level[levels][i].shape}\")\n",
    "        draft_logits = target_model(drafts_by_level[levels][i]).logits\n",
    "        normalized_logits = norm_logits(draft_logits[:, -1, :], temperature, top_k, top_p)\n",
    "        next_tok = sample(normalized_logits)\n",
    "        probs[i] = normalized_logits[0,next_tok[0].long()]\n",
    "    scores = probs * torch.exp(reward_coeff*rewards)\n",
    "    scores = scores/torch.sum(scores)\n",
    "    aligned_draft_index = sample(scores)\n",
    "    winning_block = drafts_by_level[levels][aligned_draft_index]\n",
    "    return winning_block\n",
    "\n",
    "    # x_draft = [torch.cat((x, next_tok[:,i:i+1]), dim=1) for i in range(num_samples)]                \n",
    "    # # print(\"x_draft\",x_draft.shape)\n",
    "    # x_draft_text = [tokenizer.decode(x_draft[i][0], skip_special_tokens=True) for i in range(num_samples)]\n",
    "    # rewards = torch.zeros(num_samples,device=x.device)\n",
    "    # for i in range(num_samples):\n",
    "    #     rewards[i] = return_reward(tokenizer.decode(x_draft[i][0], skip_special_tokens=True), x_draft_text[i])\n",
    "    \n",
    "    # scores = normalized_logits[0,next_tok[0].long()] * torch.exp(reward_coeff*rewards)\n",
    "    # scores = scores/torch.sum(scores) \n",
    "    # aligned_token_index = sample(scores)\n",
    "    # aligned_token = next_tok[:,aligned_token_index]\n",
    "    # return aligned_token\n",
    "\n",
    "def small_tree(target_model, x, num_samples=5,levels=None):\n",
    "    q_logits = target_model(x).logits\n",
    "    normalized_logits = norm_logits(q_logits[:, -1, :], temperature, top_k, top_p)\n",
    "    next_tok = sample(normalized_logits,num_samples=num_samples)\n",
    "    x_draft = [torch.cat((x, next_tok[:,i:i+1]), dim=1) for i in range(num_samples)]                \n",
    "    # print(\"x_draft\",x_draft.shape)\n",
    "    x_draft_text = [tokenizer.decode(x_draft[i][0], skip_special_tokens=True) for i in range(num_samples)]\n",
    "    rewards = torch.zeros(num_samples,device=x.device)\n",
    "    for i in range(num_samples):\n",
    "        rewards[i] = return_reward(tokenizer.decode(x_draft[i][0], skip_special_tokens=True), x_draft_text[i])\n",
    "    \n",
    "    scores = normalized_logits[0,next_tok[0].long()] * torch.exp(reward_coeff*rewards)\n",
    "    scores = scores/torch.sum(scores) \n",
    "    aligned_token_index = sample(scores)\n",
    "    aligned_token = next_tok[:,aligned_token_index]\n",
    "    return aligned_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "speculative sampling:   0%|          | 0/25 [00:13<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = approx_model.device\n",
    "\n",
    "model_name = \"Skywork/Skywork-Reward-Llama-3.1-8B\"\n",
    "\n",
    "correlatations = []\n",
    "seq_len = prefix.shape[1]\n",
    "T = seq_len + max_len\n",
    "\n",
    "assert prefix.shape[0] == 1, \"input batch size must be 1\"\n",
    "\n",
    "start_time = time.time()\n",
    "with tqdm(total=T, desc=\"speculative sampling\") as pbar:\n",
    "    while prefix.shape[1] < T:\n",
    "        # q = M_q[prefix + x_0, x_1, .., x_(gamma-2)]\n",
    "        x = prefix\n",
    "        prefix_len = prefix.shape[1]\n",
    "        for _ in range(gamma):\n",
    "            # p.logits shape (batch, seq, vocab)\n",
    "            branching_factor = 3\n",
    "            levels=2\n",
    "            # aligned_token = leveled_tree(target_model, x, branching_factor,levels=2)\n",
    "            # print(aligned_token.shape)\n",
    "            # x = torch.cat((x, aligned_token), dim=1)\n",
    "            x = leveled_tree(target_model, x, branching_factor,levels=3)\n",
    "        prefix = x\n",
    "        print(prefix.shape)\n",
    "execution_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat hopped onto lap, head buried in\\nhuman whisper-sang a lullabi\\nof catnip-scents\\nAs the world outside\\nf'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded = tokenizer.decode(prefix[0], skip_special_tokens=True)\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-17.875"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_reward(None, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
