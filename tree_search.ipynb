{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea734c13924547cfb818f86e3ccb487f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81df60d744cd4ae7ae23327f864c56af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/42.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6917801534374e5ca64ad573a927f2b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9120d3b8ed3d47d285beea75f3b84d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00012.safetensors:   0%|          | 0.00/4.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962beecf6a374045afa459361e326a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00012.safetensors:   0%|          | 0.00/4.87G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "device = \"cuda:1\"\n",
    "# model_name = \"Skywork/Skywork-Reward-Llama-3.1-8B\"\n",
    "model_name = \"Skywork/Skywork-Reward-Gemma-2-27B\"\n",
    "rm = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=device,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    "    num_labels=1,\n",
    ")\n",
    "rm_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "def rate_answer(question,answer):\n",
    "    conv1 = [{\"role\": \"user\", \"content\": question}, {\"role\": \"assistant\", \"content\": answer}]\n",
    "    conv1_formatted = rm_tokenizer.apply_chat_template(conv1, tokenize=False)\n",
    "    conv1_tokenized = rm_tokenizer(conv1_formatted, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        score1 = rm(**conv1_tokenized).logits[0][0].item()\n",
    "    return score1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vllm serve NousResearch/Meta-Llama-3-8B-Instruct --dtype auto --api-key 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "model = \"NousResearch/Meta-Llama-3-8B-Instruct\"\n",
    "api_key = \"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\"\n",
    "base_url=\"http://localhost:8000/v1\"\n",
    "\n",
    "from openai import OpenAI\n",
    "import re\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=base_url,\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "def chat_completion_request_openai(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    chat_response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    temperature=1.0,\n",
    "    max_tokens=1500\n",
    "    )\n",
    "    if chat_response.choices:\n",
    "        completion_text = chat_response.choices[0].message.content\n",
    "    else:\n",
    "        completion_text = None\n",
    "    return completion_text\n",
    "\n",
    "def get_answer(question, thoughts=''):\n",
    "    prompt = (\n",
    "    f\"Question: {question}\\n\"\n",
    "    f\"Previous thoughts and answers: {thoughts}\\n\"\n",
    "    \"Please improve the draft answer based on the previous answers. Return output in this manner:\\n\"\n",
    "    \"Reasoning Process: <step-by-step reasoning process>\\n\"\n",
    "    \"Final answer: <imrpoved and verified answer>\\n\"\n",
    "    )\n",
    "    return chat_completion_request_openai(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "max_children = 2\n",
    "exploration_weight = 1.41\n",
    "\n",
    "node_count = 0\n",
    "\n",
    "class Node:\n",
    "    def __init__(self,question,answer,prev_answers='',parent=None):\n",
    "        global node_count\n",
    "        self.question = question\n",
    "        self.answer = answer\n",
    "        self.prev_answers = prev_answers\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        self.reward = 0.0\n",
    "        self.value = 0.0\n",
    "        self.visits = 0\n",
    "        self.name = node_count\n",
    "        node_count += 1\n",
    "\n",
    "    def is_fully_expanded(self):\n",
    "        # check if we can expand further\n",
    "        return len(self.children) >= max_children\n",
    "    \n",
    "    def best_child(self):\n",
    "        #return index of best child\n",
    "        choice_weights = []\n",
    "        for child in self.children:\n",
    "            if child.visits == 0:\n",
    "                weight = float('inf')\n",
    "            else:\n",
    "                weight = child.value/child.visits + exploration_weight* math.sqrt((2*math.log(self.visits) / child.visits))\n",
    "            choice_weights.append(weight)\n",
    "        return self.children[np.argmax(choice_weights)] \n",
    "    \n",
    "    def most_visited_child(self):\n",
    "        # return most visited child\n",
    "        return max(self.children, key=lambda child:child.visits)\n",
    "    \n",
    "    def add_child(self,child_node):\n",
    "        # add child_node to current node\n",
    "        self.children.append(child_node)\n",
    "        child_node.parent = self\n",
    "\n",
    "class MCTS:\n",
    "    def __init__(self,question='',max_iterations=3):\n",
    "        self.question = question\n",
    "        self.max_iterations = max_iterations\n",
    "        first_answer = get_answer(question)\n",
    "        self.root = Node(question,first_answer)\n",
    "        self.best_node = None\n",
    "        self.best_value = -float('inf')\n",
    "        self.root.reward = self.evaluate(self.root)\n",
    "        self.backpropagate(self.root)\n",
    "    def search(self):\n",
    "        for i in range(self.max_iterations):\n",
    "            print(f\"Iteration: {i}/{self.max_iterations}\")\n",
    "            node = self.select(self.root)\n",
    "            print(f\"Selected node: {node.name}\")\n",
    "            if node.visits > 0:\n",
    "                node = self.expand(node)\n",
    "            # if not node.is_fully_expanded():\n",
    "            #     node = self.expand(node)\n",
    "            node.reward = self.evaluate(node)\n",
    "            print(f\"Assigned reward for node {node.name} is: {node.reward}\")\n",
    "            self.backpropagate(node)\n",
    "        # print(f\"Visits to most visited child: {self.root.most_visited_child().visits}\")\n",
    "        # return self.root.most_visited_child() \n",
    "        return self.best_node\n",
    "    def select(self, node):\n",
    "        while node.is_fully_expanded() and node.children:\n",
    "            # if node has a child and it is fully expanded, go deep\n",
    "            # if at a leaf or not fully expanded, return that node and expand\n",
    "            node = node.best_child()\n",
    "        return node\n",
    "    def expand(self, node):\n",
    "        for j in range(max_children - len(node.children)):\n",
    "            child_answer = get_answer(self.question, node.prev_answers)\n",
    "            child_node = Node(self.question, answer=child_answer, prev_answers=node.prev_answers+node.answer)\n",
    "            node.add_child(child_node)\n",
    "            print(f'Added a new node {child_node.name} to node {node.name}')            \n",
    "            # print(f\"\\n --Answer {j}--:\\n{answer}\")\n",
    "        return random.choice(node.children)\n",
    "    def evaluate(self, node):\n",
    "        return rate_answer(self.question, node.answer)\n",
    "    def backpropagate(self, node):\n",
    "        while node is not None:\n",
    "            node.visits += 1\n",
    "            node.value += node.reward\n",
    "            if node.value/node.visits > self.best_value:\n",
    "                self.best_value = node.value/node.visits\n",
    "                self.best_node = node\n",
    "            node = node.parent\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoT:\n",
    "    def __init__(self,question='',max_rounds=3):\n",
    "        self.question = question\n",
    "        self.max_rounds = max_rounds\n",
    "        self.history = ''\n",
    "        self.nodes = []\n",
    "        self.rewards = []\n",
    "    def search(self):\n",
    "        for _ in range(self.max_rounds):\n",
    "            node_answer = get_answer(self.question, self.history)\n",
    "            node = Node(self.question,node_answer,prev_answers=self.history)\n",
    "            self.history += node_answer\n",
    "        return node\n",
    "    def evaluate(self, node):\n",
    "        return rate_answer(self.question, node.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BestofN:\n",
    "    def __init__(self,question='',N=3):\n",
    "        self.question = question\n",
    "        self.N = N\n",
    "        self.nodes = []\n",
    "        self.rewards = []\n",
    "    def search(self):\n",
    "        for i in range(self.N):\n",
    "            print(f\"Iteration: {i}/{self.N}\")\n",
    "            node = Node(self.question,get_answer(self.question))\n",
    "            print(f\"Selected node: {node.name}\")\n",
    "            reward = self.evaluate(node)\n",
    "            node.reward = reward\n",
    "            print(f\"Assigned reward for node {node.name} is: {reward}\")\n",
    "            self.nodes.append(node)\n",
    "            self.rewards.append(reward)\n",
    "        best_index = np.argmin(self.rewards)\n",
    "        best_node = self.nodes[best_index]\n",
    "        return best_node\n",
    "    def evaluate(self, node):\n",
    "        return rate_answer(self.question, node.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0/3\n",
      "Selected node: 3\n",
      "Assigned reward for node 3 is: 0.765625\n",
      "Iteration: 1/3\n",
      "Selected node: 4\n",
      "Assigned reward for node 4 is: -5.6875\n",
      "Iteration: 2/3\n",
      "Selected node: 5\n",
      "Assigned reward for node 5 is: -5.1875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Here is the reasoning process:\\n\\nReasoning Process:\\n\\n1. The question asks about the capital of France.\\n2. I will not accept a previous thought or answer, because this is the starting point of the conversation.\\n3. The first step is to provide a draft answer.\\n4. The draft answer will be the most common or obvious answer, which is \"Paris\".\\n5. Verify the answer through cross-checking with credible sources.\\n\\nFinal answer: \\n\\nThe capital of France is Paris.',\n",
       " -5.6875)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is the capital of France?\"\n",
    "bon = BestofN(question,N=3)\n",
    "best_node = bon.search()\n",
    "best_node.answer, best_node.reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0/4\n",
      "Selected node: 7\n",
      "Added a new node 8 to node 7\n",
      "Added a new node 9 to node 7\n",
      "Assigned reward for node 8 is: -11.9375\n",
      "Iteration: 1/4\n",
      "Selected node: 9\n",
      "Assigned reward for node 9 is: -10.25\n",
      "Iteration: 2/4\n",
      "Selected node: 9\n",
      "Added a new node 10 to node 9\n",
      "Added a new node 11 to node 9\n",
      "Assigned reward for node 11 is: -12.8125\n",
      "Iteration: 3/4\n",
      "Selected node: 10\n",
      "Assigned reward for node 10 is: -6.625\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the capital of France?\"\n",
    "mcts = MCTS(question,max_iterations=4)\n",
    "best_node_mcts = mcts.search()\n",
    "# print(best_node.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_node_mcts.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mcts.root.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcts.root.name\n",
    "first_gen_nodes = mcts.root.children\n",
    "print(mcts.root.name,mcts.root.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_gen_nodes = []\n",
    "for first_gen in first_gen_nodes:\n",
    "    print(first_gen.name, first_gen.value)\n",
    "    second_gen_nodes += first_gen.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for second_gen in second_gen_nodes:\n",
    "    print(second_gen.name, second_gen.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_node.name, best_node.value)\n",
    "print(mcts.root.answer)\n",
    "print(mcts.root.children[0].answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mcts.root.children[1].answer)\n",
    "print(mcts.root.children[2].answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
